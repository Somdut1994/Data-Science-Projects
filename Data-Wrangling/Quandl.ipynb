{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c16f0",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a2f50",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from static_grader import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c65c79",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Quandl Miniproject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dee830",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d994cd",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Data provider [Quandl](https://www.quandl.com/) offers a vast array of free and paid databases, all accessible with the same Python API (application program interface). Quandl aggregates data from many sources, ranging from scientific to economic to government related topics. They conveniently provide the data to you in powerful Pandas DataFrames.\n",
    "\n",
    "**In this project, you will gain experience working with Python and Pandas using the data from Quandl.**\n",
    "\n",
    "At the completion of this project, you will understand how to access all of the Quandl data and how to then wrangle that data in Pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ed2db",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Getting Data From Quandl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcc2c6",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "To use Quandl you will have to create an API key. The purpose of the API key is to make it easy for Quandl to track the usage of their data (creating data for them to study!) and for them to ensure that no one user is abusing their system with too many requests.\n",
    "\n",
    "Create an API key by first creating an account on [Quandl](https://www.quandl.com/). You can log in with your Google, GitHub or LinkedIn accounts if you like.\n",
    "\n",
    "After creating an account, access your *Account Settings* from the *Me* dropdown in the upper right corner. Then click on the *API KEY* link on the left below *PASSWORD*. Save the API Key: you'll need that in a moment.\n",
    "\n",
    "There is [documentation](https://www.quandl.com/docs/api?python#) available for the API. You'll need to look through that to find a few pieces of information, but we will walk you through the basics right now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007a33d",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "### Test Query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f3cb7",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Quandl provides a Python module that allows for easy access to their API.  Let's make sure we have the right version installed.  It should start with a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53dd0c",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "print(quandl.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c55c0d",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, tell Quandl about the API key you created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466ab37",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = '<API KEY>'  # Fill in your value here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abebed",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we will access some Sunspot data. Visit Quandl's page for the [Solar Influences Data Analysis Center](https://www.quandl.com/data/SIDC/SUNSPOTS_D-Total-Sunspot-Numbers-Daily).\n",
    "\n",
    "This is daily data collected by the Royal Observatory of Belgium starting in 1818. Observe in the upper right hand corner of the page you will find a *Quandl Code*. You will need this code to access this specific data set. Each data set has its own code, which you can use to download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc1989",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "sunspots = quandl.get('SIDC/SUNSPOTS_D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6567e3",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The string `SIDC/SUNSPOTS_D` is a code for retrieving specific data offered by Quandl. `SIDC` refers to the Royal Observatory database, and `SUNSPOTS_D` is a specific data set in that database.\n",
    "\n",
    "Let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c215309",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "sunspots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad16b54",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "sunspots['Daily Sunspot Number'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48284a",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "That's how easy Quandl is! Find the Quandl code for the data you want and then call the `get` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed7b87",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84519229",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "At the end of each question is a call to the grader. For all but one of the questions we ask you to pass to the grader a list containing your answers. Often, we give you a placeholder variable to pass to `grader.score()`, so you can check that you understand the format of the answer. Additionally, it contains a sample of one of the correct answers; you can use it as a check. Note, you **should not** modify the first argument of `grader.score()`; that tells the grader what question to use when evaluating your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5340e1",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 1: Daily change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf54fe3",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We want to find the daily percentage change in the closing price for the first 100 trading days of 2016 for Tableau Software (ticker symbol DATA).  This should be returned as a list of 100 tuples of (date, percentage).\n",
    "- Format the dates as strings like \"7/04/16\" for July 4th or \"11/01/16\" for November 1st.\n",
    "  - **IMPORTANT**: look closely at the date format. The day has a leading zero but the month does not. The year is represented with two digits. Admittedly this is not a standard way of representing dates. The goal is to get you to think carefully about date formatting [directives](http://strftime.org/).\n",
    "- The returns will be percentages, not fractions. Therefore, submit a return of one-and-a-half percent as 1.5, not 0.015.\n",
    "Quandl provides stock prices in the \"WIKI Stock Prices\" database.  When interacting with a new API, you may need to search the documentation to learn what data is available and how to access it. The documentation on the [Python API](https://docs.quandl.com/docs/python-time-series) indicates that we can access data sets via their Quandl code.  The [documentation for this data set](https://www.quandl.com/databases/WIKIP/documentation/about) links to a compressed CSV containing all the possible Quandl codes. The code below will download the Quandl codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241f795",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://s3.amazonaws.com/dataincubator-course/quandl-codes/WIKI_codes.zip -nc\n",
    "unzip -u WIKI_codes.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cac58d",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "wiki_codes = pd.read_csv('WIKI-datasets-codes.csv', header=None,\n",
    "                    names=('Code', 'Description'))\n",
    "wiki_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eb414",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Find the Quandl code in `wiki_codes` for Tableau Software. Use this Quandl code with `quandl.get()`, using the `start_date='2015-12-31'` keyword argument to get only the data since 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02788b8",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "prices = quandl.get(..., start_date='2015-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e81df0",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The DataFrame you get should have several hundred rows and 12 columns, with a `datetime` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d2265",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# Double check which code corresponds to Tableau Software\n",
    "grader.check(prices.shape[1] == 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2b72b",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "print(type(prices.index))\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8562d54",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The only column we need is the \"Adj. Close\" column, which is adjusted for corporate actions like dividends and splits.  Use the `.pct_change()` method on this column to get the daily fractional change and then adjust it to be a percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a5574",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "close_change = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f594d",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The dates are the index of the dataframe.  They can be made into a column with the `.reset_index()` method, or accessed directly with via the `.index` property of the dataframe or `close_change` series.  Once you have the dates, use the `.strftime()` method to format them as strings, with [these directives](http://strftime.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270954df",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "date_str = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73acf77",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Finally, combine these two results into a list of tuples.  There are several approaches to this, including:\n",
    "1. Make the two series into columns in the same dataframe.  Use a list comprehension over the [`.itertuples()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples) generator to produce a list of tuples.\n",
    "2. Use [`zip()`](https://docs.python.org/3/library/functions.html#zip) to join the two series into a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22190d",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "wiki_data_tuples = list(zip(date_str, close_change))\n",
    "\n",
    "print(wiki_data_tuples[0])\n",
    "print(len(wiki_data_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39716cd3",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "There are two problems with this:\n",
    "1. The first element is a `NaN` from the last day of 2015.\n",
    "2. There are more than 100 tuples.\n",
    "\n",
    "Select the first 100 days of 2016, and submit those to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4142fd",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "wiki_data_tuples_all = list(zip(date_str, close_change))\n",
    "wiki_data_tuples = ...\n",
    "\n",
    "grader.score('quandl__wiki_data', wiki_data_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c6d06",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Bureau of Labor Statistics codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a58d1",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The rest of the questions will use data provided by the US [Bureau of Labor Statistics](https://www.quandl.com/data/BLSE?keyword=). Among other things, they track monthly employment numbers by industry for each state.\n",
    "\n",
    "We are specifically interested in their *State and Area Employment, Hours, and Earnings* data, as described in their [documentation](https://www.quandl.com/data/BLSE/documentation/documentation). The documentation describes the *Code Nomenclature* for data files for all of the combinations of states and industries and seasonally/not seasonally adjusted data.\n",
    "\n",
    "Each of these data sets looks like this one:\n",
    "\n",
    "https://www.quandl.com/data/BLSE/SMS01000004300000001-All-Employees-In-Thousands-Transportation-and-Utilities-Alabama\n",
    "\n",
    "For these questions you will need to combine all of the data tables in this subgroup of the `BLS` database. There will be about 1118 tables in total. We will develop a process for downloading them one by one using `quandl.get()` on the Quandl codes for individual tables, and then concatenate them all into one data set.\n",
    "\n",
    "Quandl provides a convenient database metadata file containing the `BLSE` data set codes and descriptions. We'll download this file and pick out the *State and Area Employment, Hours, and Earnings* data table codes based on the table descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d34a8",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://s3.amazonaws.com/dataincubator-course/BLSE/BLSE_codes.zip -nc\n",
    "unzip -u BLSE_codes.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738d3a0",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, we can load all of the metadata into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68981e",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "blse_codes = pd.read_csv('BLSE-datasets-codes.csv', header=None,\n",
    "                    names=('Code', 'Description'))\n",
    "blse_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ea5b8",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "All of the tables with relevant employment information have a description that begins, \"All Employees\".  Create a new data frame that contains only those rows.  There should be 1118 in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a0a69",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "valid_rows = ...\n",
    "valid_codes = blse_codes[valid_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765283a",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# The description should *begin* with All Employees\n",
    "grader.check(valid_codes.shape[0] == 1118)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8a043",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 2: California codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb9922",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Of those valid codes, find all that refer to California.  This can be determined from the code itself or from the description.  There should be 24 in total.  Return a list of these codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fa56f",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "california_codes = ...\n",
    "grader.score('quandl__california_codes', california_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5901e5",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd2fea",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We want to download and store the tables corresponding with each Quandl code in the `valid_codes` DataFrame.  Let's start by downloading the data from the beginning of 2006 to the end of 2015 corresponding with just one code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416274d",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "code = valid_codes.loc[0, 'Code']\n",
    "description = valid_codes.loc[0, 'Description']\n",
    "\n",
    "df = ...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb9522",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "This table contains employment numbers for a particular industry, state, etc. We will be concatenating this table with tables for other industries, states, etc. Therefore we should add columns to our dataframe to keep track of which the state, category (industry), and a flag for whether the data are adjusted.  If `df` is a dataframe, a constant column can be added with\n",
    "```python\n",
    "df['State'] = pd.Series('West Virginia', index=df.index)\n",
    "```\n",
    "We can't hard-code the values for each data set, so we will have to work out the values either by parsing the text in `description`, or from the data set's code, as [described in the documentation](https://www.quandl.com/data/BLSE-BLS-Employment-Unemployment/documentation/documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567fae90",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# It is part of the description\n",
    "state = ...\n",
    "grader.check(state == 'Maryland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd1ba6",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# It is part of the description\n",
    "category = ...\n",
    "grader.check(category == 'Telecommunications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f75a90",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# It is indicated by the code\n",
    "adjusted = ...\n",
    "grader.check(adjusted == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90467103",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now that we have these values, let's add them as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c790ba7",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "df['State'] = pd.Series(state, index=df.index)\n",
    "df['Category'] = pd.Series(category, index=df.index)\n",
    "df['Adjusted'] = pd.Series(adjusted, index=df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066c838",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, package this process into a single function, so that we can reuse it for each `BLSE` data set.  The function should accept a Quandl code and table description, and use those arguments to retrieve the data set into a dataframe, adding columns for the state, category, and adjustment flag.\n",
    "\n",
    "It's also a good idea to have this function write the dataframe to a file.  This way, if a data retrieval fails, you can rerun just that data set.  If you need to restart the notebook, you won't need to download all of the data again.\n",
    "\n",
    "You can use Pandas' `to_pickle()` and `from_pickle()` functions, or another mechanism.  The checkpoint library [ediblepickle](https://pypi.python.org/pypi/ediblepickle/1.1.3) could also be used to streamline the process so that the time-consuming code will only be run when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7c615",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def get_data(code, description):\n",
    "    # Download data\n",
    "    # Add columns\n",
    "    # Save locally\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "get_data(code, description).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065560b4",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Test that function for several Quandl codes and table descriptions from `valid_codes` by changing `idx` in the cell below to make sure your function works as you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978f58f",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "test_df = get_data(*valid_codes.iloc[idx])\n",
    "\n",
    "# Check the range of dates that is being downloaded\n",
    "grader.check(test_df.shape[0] == 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab536942",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "print(valid_codes.iloc[idx]['Description'])\n",
    "print(test_df['State'].unique())\n",
    "print(test_df['Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c583e06",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 3: Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0623e",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Once your function is ready, submit it to the grader.  The grader will pass it some arguments and check that you retrieved the correct data.\n",
    "\n",
    "*N.B. Your function must be set up to take two arguments: the code and the description, in that order.  It must return a DataFrame with four columns, the value, state, category, and adjusted flag.  The order of the columns does not matter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157304d",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "grader.score(\"quandl__download_data\", get_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e58fa",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Getting all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0aaf34",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now that we are sure the function works correctly, we will iterate over `valid_codes`, passing each Quandl code and table description to the function.\n",
    "\n",
    "Quandl limits the rate of API calls you can make. The speed of your loop might be faster than Quandl's limit. To slow it down you can tell Python to `sleep` for a short time to keep it under the threshold.\n",
    "```python\n",
    "import time\n",
    "time.sleep(0.1)  # sleep for 0.1 seconds (100 ms)\n",
    "```\n",
    "\n",
    "If you add that to your function above, we can load all of the data into a single dataframe using `pd.concat()` function and a comprehension to handle the iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b8387",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat(get_data(code, description) for code, description\n",
    "                   in valid_codes.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e810e",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Each question will pertain to either the unadjusted or the adjusted data.  You may find it easier to split each in its own dataframe.  Also, remove the `Total Private` and `Total Nonfarm` data, as these statistics are aggregations, not industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea98ba",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "df_raw = ... # Unadjusted data\n",
    "df_adj = ... # Adjusted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf1d38",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 4: State/industry pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea1d9b",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "For this question, use the *unadjusted data* to find the 100 largest state-industry pairs for December 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd155c9",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# Select out only the results from 12/2015\n",
    "dec15 = ...\n",
    "# Sort them by 'Value' and choose the top 100\n",
    "top100 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f3277",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Your answer should consist of 100 tuples of states, industry names, and employment numbers, like this: ((State, Industry), Employment #)\n",
    "\n",
    "The State and Industry names will be strings, the same as you see in the documentation.\n",
    "\n",
    "The Employment numbers will be the number of people employed on that date. Note the data is provided to you in thousands, so you will have to do some multiplication.\n",
    "\n",
    "We can do this with a list comprehension over `top100.itertuples()`.\n",
    "```Python\n",
    "state_industry_tuples = [... for x in top100.itertuples(index=False)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036c57b",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "state_industry_tuples = [(('California', 'Service-Providing'), 14362200)] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108b557",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "grader.score('quandl__state_industry_pairs', state_industry_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d223ef2",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 5: State total employed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d5668",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Using the unadjusted data, what are the total number of employed people in each state in December 2015?\n",
    "\n",
    "Your answer should consist of 53 tuples of states and employment numbers, like this: (State, Employment #)\n",
    "\n",
    "That's 50 states, plus Washington DC, Puerto Rico, and the Virgin Islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc1f22",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "state_total_employed =  [('Alabama', 3008700)] * 53\n",
    "\n",
    "grader.score('quandl__state_total_employed', state_total_employed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81acc7c7",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 6: State industry growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df6beb",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Using the unadjusted data, for each state, which industry saw the largest percent growth from December 2006 to December 2015?\n",
    "\n",
    "Your answer should consist of 53 tuples of states, industries, and percentages, like this: ((State, Industry), Percentage).\n",
    "\n",
    "The State and Industry names will be strings, the same as you see in the documentation.\n",
    "\n",
    "The Percentage will be a percentage, not fraction. Submit a return of 1.5% as 1.5, not 0.015.\n",
    "\n",
    "Start by getting the data from December 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8482a",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "dec06 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce18236",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We want to compare rows in the `dec06` and `dec15` dataframes that have the same state and category.  When operations are conducted on dataframes, rows are matched by index.  Indices can have multiple levels.  Use the `.set_index()` method with a list as an argument to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4056d",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "val06 = ...\n",
    "val15 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37b78e",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, we can do math directly on the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811022e7",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "growth = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5e2b8",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "To choose the largest for each state, we need to group the rows by state. We can only group by columns, so we first have to change the indices back to columns with `.reset_index()`, and then use `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ff234",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "by_state = ...\n",
    "\n",
    "# This check is before aggregation\n",
    "grader.check(type(by_state) == pd.core.groupby.DataFrameGroupBy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bc128",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We can pull out a group from our `DataFrameGroupBy` object for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfd978",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "alabama = by_state.get_group('Alabama')\n",
    "alabama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dba162",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Write a function that takes this dataframe and returns the row with the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1d58e",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def largest_value(df):\n",
    "    ...\n",
    "\n",
    "# Be sure to return the _row_ with the maximum value\n",
    "grader.check(largest_value(alabama)['Category'] == 'Transportation and Utilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952da73f",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we can use the group-by object's `.apply()` method to apply this function to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1897d",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "fastest_by_state = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e127a",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, convert this dataframe to a list of tuples in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70347728",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "state_industry_growth = [(('Alabama', 'Transportation and Utilities'), 4.022191400832176)] * 53\n",
    "\n",
    "grader.score('quandl__state_industry_growth', state_industry_growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb7118",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 7: Max employment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1f84e",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Using the unadjusted data, find the maximum _total national_ employment number for each industry. That is, find the number of people employed nationally in each industry during the month in which that industry peaked in our data set.\n",
    "\n",
    "Your answer should consist of 16 tuples of industries and employment numbers, like this: (Industry, Employment #)\n",
    "\n",
    "The Industry names will be strings, just like they are in the documentation.\n",
    "\n",
    "The Employment numbers will be the total number of people employed in any state in each industry. Note the data is provided to you in thousands, so you will have to do some multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cc597",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "max_employment = [('Air Transportation', 402800)] * 16\n",
    "\n",
    "grader.score('quandl__max_employment', max_employment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb15791",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 8: Quarterly non-farm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f718e7",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Using the seasonally adjusted data, what is the quarterly percent change for national total non-farm employment? (Don't forget, we removed the total non-farm from the data before, so we'll have to recover it from the original data set.)\n",
    "\n",
    "Use the last data-point in each quarter to represent the data for the quarter.\n",
    "\n",
    "The first calculated percentage will be (should be) `NaN`, which you can exclude from your answer.\n",
    "\n",
    "Your answer should be 39 tuples of dates and percentages, like this: (Date, Percentage)\n",
    "\n",
    "Format the dates as strings like \"2016-07-04\" for July 4th or \"2016-11-01\" for November 1st.\n",
    "\n",
    "The Percentage will be a percentage, not fraction. Submit a return of\n",
    "1.5% as 1.5, not 0.015.\n",
    "\n",
    "Hint: Try using a DataFrame's `.resample()` method. Don't forget when resampling that we want to take the last data-point from each quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565103d0",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "quarterly_nonfarm = [('2006-06-30', 0.33424149239997814)] * 39\n",
    "\n",
    "grader.score('quandl__quarterly_nonfarm', quarterly_nonfarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b26dbc",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 9: Third largest industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44648fba",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Using the unadjusted data, what is the 3rd largest industry in each state in December 2015? Express the employment in the 3rd largest industry as a percentage of the state's total industry employment in December 2015.\n",
    "\n",
    "Your answer should consist of 53 tuples of states, industries, and percentages, like this: ((State, Industry), Percentage).\n",
    "\n",
    "The State and Industry names will be strings, the same as you see in the documentation.\n",
    "\n",
    "The Percentage will be as percentages, not fractions. Submit a return of 1.5% as 1.5, not 0.015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17a40f",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "third_largest = [(('Alabama', 'Goods Producing'), 11.779173729517732)] * 53\n",
    "\n",
    "grader.score('quandl__third_largest', third_largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6fd99",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "*Copyright &copy; 2022 Pragmatic Institute. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
